{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model\n",
    "\n",
    "For avoiding duplication, we will make an abstract class for the regression model. This class will have the following methods:\n",
    "\n",
    "- `create_model`: This is an abstract method and will be implemented by the child classes. This method will create the regression model that will be used for training and prediction.\n",
    "\n",
    "- `set_search_params`: This method will set the hyperparameters that will be used in the grid search.\n",
    "\n",
    "- `predict`\n",
    "\n",
    "- `grid_search`\n",
    "\n",
    "- `show_metrics`: This method will show the metrics that we discussed earlier for the regression model.\n",
    "\n",
    "- `draw_predictions`: This method will draw a plot where the x axis will be the actual values and the y axis will be the predicted values.\n",
    "\n",
    "it also accepts two paramaters `scale` and `logarithm`. If `scale` is True, the model will scale the features. If `logarithm` is True, the model will also apply the power transformation to the target variable when calculating the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class RegressionModel(ABC):\n",
    "    def __init__(self, features, target, params, scale=True, logarithm=False):\n",
    "        if scale:\n",
    "            self.feature_scaler = StandardScaler()\n",
    "            self.target_scaler = StandardScaler()\n",
    "            self.features = self.feature_scaler.fit_transform(features)\n",
    "            self.target = self.target_scaler.fit_transform(target.values.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            self.feature_scaler = None\n",
    "            self.target_scaler = None\n",
    "            self.features = features\n",
    "            self.target = target.values.flatten()\n",
    "            \n",
    "        self.logarithm = logarithm\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.features, self.target, test_size=0.1, random_state=42)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "        self.model = self.create_model(params)\n",
    "        self.search_params = self.set_search_params()\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.y_pred = self.model.predict(X_test)\n",
    "        #show_metrics(self.model.predict(X_train), y_train, self.target_scaler, logarithm)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def create_model(self, params):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def set_search_params(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, features):\n",
    "        if self.feature_scaler:\n",
    "           features = self.feature_scaler.transform(features)\n",
    "        return self.model.predict(features)\n",
    "    \n",
    "    def grid_search(self):\n",
    "        grid_search = GridSearchCV(self.model, self.search_params, cv=5, scoring='neg_mean_absolute_error', n_jobs=2)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        test_score = best_model.score(self.X_test, self.y_test)\n",
    "        self.model = best_model\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "        return best_model, test_score\n",
    "    \n",
    "    def show_metrics(self):\n",
    "        show_metrics(self.y_pred, self.y_test, self.target_scaler, self.logarithm)\n",
    "    \n",
    "    def draw_predictions(self, log=False):\n",
    "        if self.target_scaler:\n",
    "            y_pred = self.target_scaler.inverse_transform(self.y_pred.reshape(-1, 1)).ravel()\n",
    "            y_test = self.target_scaler.inverse_transform(self.y_test.reshape(-1, 1)).ravel()\n",
    "        else:\n",
    "            y_pred = self.y_pred\n",
    "            y_test = self.y_test\n",
    "        \n",
    "        if log:\n",
    "            y_pred = np.power(10, y_pred)\n",
    "            y_test = np.power(10, y_test)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x=y_test, y=y_pred, color='blue', label='Predicted vs Actual')\n",
    "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Ideal Fit')\n",
    "        plt.title('Actual vs Predicted Values')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def get_feature_importance(self):\n",
    "        perm_importance = permutation_importance(self.model, self.X_train, self.y_train, n_repeats=10, random_state=42)\n",
    "        feature_importances_df = pd.DataFrame({\n",
    "                'Feature': self.features.columns,\n",
    "                'Importance': perm_importance.importances_mean\n",
    "            })\n",
    "        display(feature_importances_df.sort_values(by='Importance', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
